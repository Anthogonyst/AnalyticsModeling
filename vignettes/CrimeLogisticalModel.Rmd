---
title: "Crime Logistical Model"
author: "Anthony A, IvanTikhonov, Seung min song"
date: "`r format(Sys.time(), '%m/%d/%Y')`"
output: 
  pdf_document:
    pandoc_args: --listings
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r libraries, include=FALSE, warning=FALSE}
library(dplyr)
library(reshape2)
library(ggplot2)
library(MASS)
library(dplyr)
library(dbplyr)
library(caret)
library(lattice)
library(purrr)
library(kableExtra)
```

# Abstract

We will evaluate data related to neighborhood crime and determine if a neighborhood is above the median crime rate.
To do this, we will create a logistical model that rates either true or false.
This information is necessary to determine if a neighborhood is going through difficult times or is over-policed by authorities.
As such, our approach attempts to find a non-biased answer based on what is known.

# Datasets

Datasets are provided by CUNY School of Professional Studies for academic purposes.
It is reflective of public data gathered online.

# Data Exploration

The data has 12 features and 1 target variable.
Since our model will be logistical regression, a positive result is 1 and vice versa.

- zn: proportion of residential land zoned for large lots (over 25000 square feet) 
- indus: proportion of non-retail business acres per suburb 
- chas: a dummy var. for whether the suburb borders the Charles River (1) or not (0) 
- nox: nitrogen oxides concentration (parts per 10 million) 
- rm: average number of rooms per dwelling 
- age: proportion of owner-occupied units built prior to 1940 
- dis: weighted mean of distances to five Boston employment centers 
- rad: index of accessibility to radial highways 
- tax: full-value property-tax rate per $10,000 
- ptratio: pupil-teacher ratio by town 
- lstat: lower status of the population (percent) 
- medv: median value of owner-occupied homes in $1000s 
- target: whether the crime rate is above the median crime rate (1) or not (0)

```{r}
all_train <- read.csv("https://raw.githubusercontent.com/IvanGrozny88/DATA-621-HW3/main/crime-training-data_modified.csv")
eval <- read.csv("https://raw.githubusercontent.com/IvanGrozny88/DATA-621-HW3/main/crime-evaluation-data_modified.csv")
```

## Data structure

There are 466 observations and 13 variables in the training dataset.
Additionally, there are no missing values so imputation is not necessary on this dataset.
Our minimum sample size at n% probability would be 10*13/n so our sample size is adequate (466 > 260) where 50% of samples are expected to be over the median by definition.
Shown below is a sample of its head.

```{r}
str(all_train)
```

```{r, include=FALSE}
nrow(all_train[is.na(all_train),])
```

```{r}
#Since variables chas and target are categorical, we are going to change their class from integer to factor:

all_train$chas <- as.factor(all_train$chas)
all_train$target <- as.factor(all_train$target)
```

## Summary Statistics

Looking at the target variable, we see 237 observations are below the median crime rate and 229 are above the median crime rate. 
Thus we have roughly the same number of at risk and not-at-risk neighborhoods in our training data set.
This is good because it means that our classes are evenly balanced for our model.

```{r}
summary(all_train)
```

## Visulization of the data set

Let’s first look at the density plots of the numerical variables to view their shapes and distributions:

```{r}
datasub = reshape2::melt(all_train, id=c("chas", "target"))
ggplot(datasub, aes(x = value)) + 
    geom_density(fill = "blue") + 
    facet_wrap(~variable, scales = 'free') 
```

For categorial variable chas, we can look at a confusion matrix table to make sure that we have enough observations for all levels:

```{r}
xtabs(~ target + chas, data=all_train)
```

Then we will look at the boxplots of the numerical variables in relationship to target variable:

```{r}
ggplot(datasub, aes(x = target, y = value)) + 
    geom_boxplot() + 
    facet_wrap(~variable, scales = 'free') 
```

# Data Preparation

## Outlier Imputation

From the boxplots above, we can see there are many outliers so we are going to fix them by replacing with medians.

```{r}
train_clean_pre <- all_train 
set.seed(121)
split <- caret::createDataPartition(train_clean_pre$target, p=0.85, list=FALSE)
train_clean <- train_clean_pre[split, ]
validation <- train_clean_pre[ -split, ]
```

Let’s look at the boxplots again after the outliers being imputed with median.

```{r}
ggplot(reshape2::melt(train_clean, id=c("chas", "target")), aes(x = target, y = value)) + 
    geom_boxplot() + 
    facet_wrap(~variable, scales = 'free') 
```

# Logistical Model Building

We first create a full model by including all the variables:

```{r}
fullMod <- glm(target ~ ., data = train_clean, family = 'binomial')
summary(fullMod)
```

## Model 1 - P-values Selection

From the full model, we select the variables that have small p-values:

target ~ nox + age + rad + tax + ptratio + lstat

```{r}
logMod1 <- glm(target ~ nox + age + rad + tax + ptratio + lstat, 
               data = train_clean, 
               family = 'binomial')
summary(logMod1)
```

## Model 2 - Backward Selection

```{r}
logMod2 <- fullMod %>% stepAIC(direction = "backward", trace = FALSE)
summary(logMod2)
```

## Model 3 - Forward Selection

```{r}
# Create an empty model with no variables
emptyMod <- glm(target ~ 1, data = train_clean, family = 'binomial')
logMod3 <- emptyMod %>% 
  stepAIC(direction = "forward",
          scope = ~ zn + indus + chas + nox + rm + age + dis 
                    + rad + tax + ptratio + lstat + medv, 
          trace = FALSE)
summary(logMod3)
```

# Model Selection

```{r}
preds1 =predict(logMod1, newdata = validation)
preds2 =predict(logMod2, newdata = validation)
preds3 =predict(logMod3, newdata = validation)
preds1[preds1 >= 0.5] <- 1
preds1[preds1 < 0.5] <- 0
preds1 = as.factor(preds1)
preds2[preds2 >= 0.5] <- 1
preds2[preds2 < 0.5] <- 0
preds2 = as.factor(preds2)
preds3[preds3 >= 0.5] <- 1
preds3[preds3 < 0.5] <- 0
preds3 = as.factor(preds3)
```


```{r}
m1cM <- confusionMatrix(preds1, validation$target, mode = "everything")
m2cM <- confusionMatrix(preds2, validation$target, mode = "everything")
m3cM <- confusionMatrix(preds3, validation$target, mode = "everything")
```

```{r}
formula(logMod1) # Model 1 formula
```

```{r}
fourfoldplot(m1cM$table, color = c("#B22222", "#2E8B57"), main="Model 1")
```

```{r}
formula(logMod2) # Model 2 formula
```

```{r}
fourfoldplot(m2cM$table, color = c("#B22222", "#2E8B57"), main="Model 2")
```

```{r}
formula(logMod3) # Model 3 formula
```

```{r}
fourfoldplot(m3cM$table, color = c("#B22222", "#2E8B57"), main="Model 3")
```

accuracy and lower error rate

```{r}
temp <- data.frame(m1cM$overall, 
                   m2cM$overall, 
                   m3cM$overall) %>%
  t() %>%
  data.frame() %>%
  dplyr::select(Accuracy) %>%
  mutate(Classification_Error_Rate = 1-Accuracy)
Summ_Stat <-data.frame(m1cM$byClass, 
                   m2cM$byClass, 
                   m3cM$byClass) %>%
  t() %>%
  data.frame() %>%
  cbind(temp) %>%
  mutate(Model = c("Model 1", "Model 2", "Model 3")) %>%
  dplyr::select(Model, Accuracy, Classification_Error_Rate, Precision, Sensitivity, Specificity, F1) %>%
  mutate_if(is.numeric, round,3)# %>%
  #kable('html', escape = F) %>%
  #kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),full_width = F)
Summ_Stat
```

Model 2,3 has better AUC

```{r}
getROC <- function(model) {
    name <- deparse(substitute(model))
    pred.prob1 <- predict(model, newdata = validation)
    p1 <- data.frame(pred = validation$target, prob = pred.prob1)
    p1 <- p1[order(p1$prob),]
    rocobj <- pROC::roc(p1$pred, p1$prob, levels = c(0, 1), direction = "<")
    plot(rocobj, asp=NA, legacy.axes = TRUE, print.auc=TRUE,
         xlab="Specificity", main = name)
}
par(mfrow=c(2,2))
getROC(logMod1)
getROC(logMod2)
getROC(logMod3)
```

Based on comparison result, we eventually choose Model 2/3 (same model)

Make Prediction

```{r}
eval$chas <- as.factor(eval$chas)
prediction = predict(logMod2, newdata = eval)
prediction[prediction >= 0.5] <- 1
prediction[prediction < 0.5] <- 0
prediction = as.factor(prediction)
prediction
```


